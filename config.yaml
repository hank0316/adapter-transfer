trainer:
  learning_rate: 1.0e-4
  train_step: 6000
  logging_step: 200
  eval_step: 200
  save_step: 200
  # Arguments for trainer
  load_best_model_at_end: True
  overwrite_output_dir: True
  remove_unused_columns: False
  # Path to store the checkpoints
  ckpt_path: 'checkpoint-best'
  # Path of output log
  logging_dir: 'log'
  # Trainer will store model according to this metric
  metric_for_best_model : 'eval_acc'

model:
  name: 'roberta-base'

exp_setup:
  chain_length: 3
  tasks:
    name: ['rte', 'stsb', 'mrpc', 'cola']